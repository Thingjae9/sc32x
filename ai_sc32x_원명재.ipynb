{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_9hARVUo9L"
      },
      "source": [
        "# SC32x \n",
        "## 자연어처리 (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNUXHiLbBdp"
      },
      "source": [
        "# Part 1 : 개념 요약\n",
        "\n",
        "> 다음의 키워드에 대해서 **한 줄**로 간단하게 요약해주세요. (세션 노트를 참고하여도 좋습니다.)<br/>\n",
        "> **Tip : 아래 문제를 먼저 수행한 후 모델 학습 등 시간이 오래 걸리는 셀이 실행되는 동안 아래 내용을 작성하면 시간을 절약할 수 있습니다.**\n",
        "\n",
        "**N321**\n",
        "- Stopwords(불용어)\n",
        "- Stemming과 Lemmatization\n",
        "- Bag-of-Words\n",
        "- TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "Stopwords : 텍스트를 토큰화할 때 의미가 없는 단어로 불용어라고 불림, 이는 분석할 때 해당 단어를 제외하고 계산하기 위해 분류를 하는 것이 중요함.\n",
        "\n",
        "Stemming과 Lemmatization : 어간 추출과 표제어 추출로 토큰화된 단어들에서 Stemming은 어간추출로 단어의 뒷 부분이 제거된 것을 말하고 Lemmataiztion은 표제어 추출로 단어들을 기본 사전형 단어인 표제어로 변환하는 과정임.\n",
        "\n",
        "Bag-of-Words : 가장 단순한 벡터화 방법 중 하나로 문서나 문법에서 단어의 순서는 무시하고 단순히 단어의 빈도만을 고려해 벡터화하는 과정\n",
        "\n",
        "TF-IDF : 단어를 벡터화를 진행할 때 다른 문서에 등장하지 않는 단어에 가중치를 두어 특정 문서에만 등장하는 단어의 대표 단어를 선정하는 방식"
      ],
      "metadata": {
        "id": "NdfK-DKjF8UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**N322**\n",
        "- Word2Vec\n",
        "- fastText"
      ],
      "metadata": {
        "id": "O2go82JnF1y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "Word2Vec : 말 그대로 단어를 벡터로 나타내는 방법으로 쉽게 사용되는 임베딩 방법 중에 하나\n",
        "\n",
        "fastText : 단어를 벡터로 만드는 기법 중 하나로 Word2Vec과 가장 큰 차이점은 Word2Vec은 단어를 쪼개질 수 없는 단위라고 생각하지만 fastText는 하나의 단어에도 여러개의 단어가 존재하는 것으로 인식함."
      ],
      "metadata": {
        "id": "EIwLcmK4GDxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N323**\n",
        "- RNN\n",
        "- LSTM, GRU\n",
        "- Attention"
      ],
      "metadata": {
        "id": "Oyu706gAF4L8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "RNN : 순환 신경망으로 출력되는 벡터가 다시 입력되는 특성이 있기 때문에 순환 신경망이라는 이름이 붙음. 장점으로는 어떤 길이의 sequential 데이터라도 처리할 수 있고, 단점으로는 병렬화 불가, 기울기 소실 등이 있음.\n",
        "\n",
        "LSTM, GRU : LSTM은 RNN의 구조에서 기울기 소실 문제를 해결하기 위해 forget, input, output 게이트를 추가한 것으로 뒷쪽 시퀀스의 정보에 비중을 결정함과 동시에 앞쪽 시퀀스 정보를 잃지 않는 방법임, GRU는 LSTM의 구조를 조금 더 단순화 한 것으로 하나의 게이트에서 forget, input 게이트를 제어하고 LSTM구조에 있던 cell-state를 통일시켜 제거하고 output 게이트도 제거한 것\n",
        "\n",
        "Attention : RNN의 단점인 기울기 소실로부터의 장기 의존성 문제를 해결하기 위해, 각 인코더의 Time-step마다 생성되는 hidden-state 벡터를 간직하는 방식"
      ],
      "metadata": {
        "id": "cWe1aBzTGFy5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07_yjCgbBdp"
      },
      "source": [
        "# Part 2 : Fake/Real News Dataset\n",
        "\n",
        "한 주간 자연어처리 기법을 배우면서 여러분은 다양한 기술들을 접했습니다.<br/>\n",
        "어떻게 텍스트 데이터를 다뤄야 하는지, 텍스트를 벡터화 하는 법, 문서에서 토픽을 모델하는 법 등 다양한 NLP 기법을 배웠는데요.<br/>\n",
        "이번 스프린트 챌린지에선 [Fake/Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)을 사용하여 배운 것들을 복습해보는 시간을 갖겠습니다.\n",
        "\n",
        "**주의 : 모델의 성능을 최대한 끌어올리는 것이 아닌 모델 구동에 초점을 맞춰주세요.<br/>\n",
        "모든 문제를 완료한 후에도 \"시간이 남았다면\" 정확도를 올리는 것에 도전하시는 것을 추천드립니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BCX5K0nP0ZKQ"
      },
      "outputs": [],
      "source": [
        "# 코드 실행 전 seed를 지정하겠습니다.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08-JiyNbdQy"
      },
      "source": [
        "## 2.0 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyndWa5hxEmk"
      },
      "source": [
        "- 위 캐글 링크에서 데이터셋을 받아 업로드 합니다.<br/>\n",
        "(직접 업로드하게 되면 시간이 꽤 걸리므로 **drive_mount** 나 **kaggle 연동**하시는 것을 추천드립니다.)\n",
        "\n",
        "- 'label' 열을 만들어 Fake = 1, True = 0 로 레이블링해줍니다.\n",
        "- 두 파일을 합쳐 하나의 데이터프레임에 저장해 준 후 데이터를 섞어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iOMlwfuM8xG",
        "outputId": "c0afb452-d089-4576-a2e8-f6ccbf4f7c4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/colab/Fake.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/colab/True.csv')"
      ],
      "metadata": {
        "id": "DTwjLDzlNOpr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'] = 1\n",
        "df2['label'] = 0"
      ],
      "metadata": {
        "id": "qi0vDnhfNZ6x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1,df2])\n",
        "df_total = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "lGqvrjK2Ny8M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_total.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "g7Y6eYxFOgkF",
        "outputId": "e1e8db68-4898-488f-d4ce-c82f39ada46c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
              "1  Trump drops Steve Bannon from National Securit...   \n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
              "4  Donald Trump heads for Scotland to reopen a go...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
              "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
              "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
              "3  On Monday, Donald Trump once again embarrassed...          News   \n",
              "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
              "\n",
              "                  date  label  \n",
              "0    February 13, 2017      1  \n",
              "1       April 5, 2017       0  \n",
              "2  September 27, 2017       0  \n",
              "3         May 22, 2017      1  \n",
              "4       June 24, 2016       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1583e700-45f0-465e-b829-d73515075881\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1583e700-45f0-465e-b829-d73515075881')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1583e700-45f0-465e-b829-d73515075881 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1583e700-45f0-465e-b829-d73515075881');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_total"
      ],
      "metadata": {
        "id": "2WqjoPXDN8EE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbxEHBanUo9d"
      },
      "source": [
        "## 2.1 TF-IDF 를 활용하여 특정 뉴스와 유사한 뉴스 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4R5mLMS5c2I"
      },
      "source": [
        "시간상 특별한 **전처리 없이** 아래 태스크를 수행하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2B-6Wkk5YGD"
      },
      "source": [
        "### 2.1.1 TFidfVectorizer를 사용하여 문서-단어 행렬(Document-Term Matrix) 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0Kw9OQwmUo9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "17fdf5d3-bd08-4274-f0d0-88ac06b4d774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        00  000   10  100   11   12        13        14        15   16  ...  \\\n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  0.031768  0.000000  0.000000  0.0  ...   \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "...    ...  ...  ...  ...  ...  ...       ...       ...       ...  ...  ...   \n",
              "44893  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "44894  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.053852  0.0  ...   \n",
              "44895  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "44896  0.0  0.0  0.0  0.0  0.0  0.0  0.462668  0.130156  0.000000  0.0  ...   \n",
              "44897  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  ...   \n",
              "\n",
              "       yes  yesterday  york     young  youth  youtube  zero  zika      zone  \\\n",
              "0      0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "1      0.0        0.0   0.0  0.029483    0.0      0.0   0.0   0.0  0.000000   \n",
              "2      0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "3      0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "4      0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "...    ...        ...   ...       ...    ...      ...   ...   ...       ...   \n",
              "44893  0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "44894  0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "44895  0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "44896  0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.030496   \n",
              "44897  0.0        0.0   0.0  0.000000    0.0      0.0   0.0   0.0  0.000000   \n",
              "\n",
              "       zuma  \n",
              "0       0.0  \n",
              "1       0.0  \n",
              "2       0.0  \n",
              "3       0.0  \n",
              "4       0.0  \n",
              "...     ...  \n",
              "44893   0.0  \n",
              "44894   0.0  \n",
              "44895   0.0  \n",
              "44896   0.0  \n",
              "44897   0.0  \n",
              "\n",
              "[44898 rows x 3000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d03aa826-5093-4c2f-a89d-ab076588d5d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>...</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zero</th>\n",
              "      <th>zika</th>\n",
              "      <th>zone</th>\n",
              "      <th>zuma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44893</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44894</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44895</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44896</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.462668</td>\n",
              "      <td>0.130156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030496</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44897</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44898 rows × 3000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d03aa826-5093-4c2f-a89d-ab076588d5d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d03aa826-5093-4c2f-a89d-ab076588d5d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d03aa826-5093-4c2f-a89d-ab076588d5d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=3000)\n",
        "dtm_tfidf = tfidf.fit_transform(df['text'])\n",
        "dtm_tfidf = pd.DataFrame(dtm_tfidf.todense(), columns=tfidf.get_feature_names())\n",
        "dtm_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTMNUMM5WgQ"
      },
      "source": [
        "### 2.1.2 KNN 알고리즘을 사용하여 유사한 문서 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lhqO6dqFkO2"
      },
      "source": [
        "- **42번 인덱스의 문서**와 가장 유사한 **5개 문서(42번 포함)의 인덱스**와 **해당 인덱스의 레이블**을 나타내주세요.\n",
        "- NN 모델의 파라미터 중 `algorithm = 'kd_tree'` 로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8jjaQO8O6UKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4ad11b-1038-484f-9fb9-aef00d0005a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.kneighbors([dtm_tfidf.iloc[42]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB0KnOlaPWGs",
        "outputId": "fd0ea14f-5b5a-467e-f137-1112b1a3c876"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.98598258, 0.98690012, 1.        ]]),\n",
              " array([[   42, 33954, 24997, 15323,  1639]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "답 : [42, 33954, 24997, 15323, 1639]"
      ],
      "metadata": {
        "id": "dAG1wmGIPnrl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQSPbQE7P8b"
      },
      "source": [
        "## 2.2 Keras Embedding을 사용하여 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEl8iU6j8I4M"
      },
      "source": [
        "### 2.2.0 데이터셋 split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIQqkDeOFkO3"
      },
      "source": [
        "- Train, Test 데이터셋으로 분리(Split)하여 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "55XSZyY_Sj54"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG4FbrKxRJEo",
        "outputId": "3d7df2d2-d899-4e75-e668-b76427694801"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35918,), (35918,))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xXxSMn7fyt"
      },
      "source": [
        "### 2.2.1 단어 벡터의 평균을 이용하여 분류해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ZsjAVg7ndG"
      },
      "source": [
        "N322에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길고 시간이 오래 걸리므로 시간상 epoch 수를 **10 이하**로 하는 것을 추천드립니다.<br/>\n",
        "모델 구동이 목적이므로 임베딩 차원 수를 크지 않게(50이하)로 설정해주세요.<br/>\n",
        "**권장사항 : `max_len` 은 텍스트 길이 평균보다 높게 설정해주세요.**<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.str.len().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOXP47N8Rw66",
        "outputId": "be95e535-29a1-4582-e22c-9250b1d2293c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2465.175009744418"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dHber3qBBwOl"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [txt for txt in X_train]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 50)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "X_train_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "max_len = 2500\n",
        "X_train=pad_sequences(X_train_encoded, maxlen=max_len, padding='post')\n",
        "\n",
        "test_sentences = [txt for txt in X_test]\n",
        "X_test_encoded = tokenizer.texts_to_sequences(test_sentences)\n",
        "X_test=pad_sequences(X_test_encoded, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "def get_vector(word):\n",
        "    \"\"\"\n",
        "    입력 단어가 vocab 에 있는 단어일 경우 임베딩 벡터를 반환\n",
        "    \n",
        "    Args:\n",
        "        word: 입력 단어 -> str\n",
        "    \"\"\"\n",
        "    if word in df:\n",
        "        return df[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "VnqF57rNZxmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model1.add(GlobalAveragePooling1D()) # 입력되는 단어 벡터의 평균을 구하는 함수입니다.\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model1.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYAulD5sjbkX",
        "outputId": "581676c6-2869-490c-9696-073767178a22"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "449/449 [==============================] - 90s 199ms/step - loss: 0.6924 - acc: 0.5239 - val_loss: 0.6927 - val_acc: 0.5146\n",
            "Epoch 2/10\n",
            "449/449 [==============================] - 95s 211ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6928 - val_acc: 0.5146\n",
            "Epoch 3/10\n",
            "449/449 [==============================] - 101s 226ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 4/10\n",
            "449/449 [==============================] - 84s 188ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 5/10\n",
            "449/449 [==============================] - 84s 187ms/step - loss: 0.6919 - acc: 0.5246 - val_loss: 0.6928 - val_acc: 0.5146\n",
            "Epoch 6/10\n",
            "449/449 [==============================] - 89s 199ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 7/10\n",
            "449/449 [==============================] - 82s 183ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 8/10\n",
            "449/449 [==============================] - 89s 199ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 9/10\n",
            "449/449 [==============================] - 87s 193ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 10/10\n",
            "449/449 [==============================] - 87s 194ms/step - loss: 0.6920 - acc: 0.5246 - val_loss: 0.6929 - val_acc: 0.5146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4964280310>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 =  np.round(model1.evaluate(X_test, y_test),4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC9RnLbUjdB0",
        "outputId": "785c9feb-f2ff-42ea-ac67-917d2d70ea58"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 24s 84ms/step - loss: 0.6919 - acc: 0.5245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SzUwLkcAK1A"
      },
      "source": [
        "### 2.2.2 LSTM을 사용하여 텍스트 분류 수행해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UZ9ZqOAIjw"
      },
      "source": [
        "N323에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길어 시간이 매우 오래 걸리므로 <br/>\n",
        "**층을 최소한으로 쌓고**, epoch 수를 **3 이하**로 하는 것을 추천드립니다.<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "6FNS4RieTEFh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9PLNlzEVBSyE"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "max_words = 50\n",
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ZFOuWCTJmA",
        "outputId": "7298ea8a-d5f1-487d-ba73-f62559b933b8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 2500)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 2500, 50)          2500      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,837\n",
            "Trainable params: 48,837\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=3,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQcq9jG-Tkr1",
        "outputId": "cc1d2a50-5a29-4905-9a91-9cedb4024928"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "225/225 [==============================] - 1670s 7s/step - loss: 0.6924 - accuracy: 0.5227 - val_loss: 0.6936 - val_accuracy: 0.5146\n",
            "Epoch 2/3\n",
            "225/225 [==============================] - 1608s 7s/step - loss: 0.6923 - accuracy: 0.5230 - val_loss: 0.6929 - val_accuracy: 0.5146\n",
            "Epoch 3/3\n",
            "225/225 [==============================] - 1571s 7s/step - loss: 0.6921 - accuracy: 0.5244 - val_loss: 0.6932 - val_accuracy: 0.5146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49e37009d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(X_test,y_test)\n",
        "print('Test set\\n  Loss, Accuracy =  ({:0.4f}, {:0.4f})'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbntqLCzeecC",
        "outputId": "35e375b0-50e5-4d5e-ed0b-1a7d6aa13fdf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 109s 388ms/step - loss: 0.6920 - accuracy: 0.5245\n",
            "Test set\n",
            "  Loss, Accuracy =  (0.6920, 0.5245)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNOs2wmBV1z"
      },
      "source": [
        "### 2.2.3 위에서 실행한 내용에 대해 다시 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMR2t2wOEPYm"
      },
      "source": [
        "#### a) 데이터셋을 학습할 때 사용하는 `pad_sequences`  메서드에 대해 설명해주세요.<br/>어떤 기능을 하나요? 모델을 학습할 때 왜 필요한가요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7_ECWSYQ4JV"
      },
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "입력되는 시퀀스의 길이가 모두 다르기 때문에 max_len을 통해 입력되는 단어의 길이를 맞춰주기 위해 입력의 길이의 뒤나 앞에 0을 넣어주는 작업을 말함. 모델을 학습할 때 이 작업이 필요한 이유는 신경망에 대한 입력은 길이가 같아야 하므로 이 과정을 진행해야 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeZ6AcloEYD5"
      },
      "source": [
        "#### b) 2.2.1과 2.2.2에서 사용한 각 모델의 evaluation 성능은 어떻게 나왔나요?<br/>각 모델의 장단점은 무엇이라고 생각하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SyqQzzHQ4EP"
      },
      "source": [
        "***이곳에 답안을 입력해주세요***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUwKojAGM82f"
      },
      "source": [
        "#### c) 종래의 RNN(Recurrent Neural Networks) 대신 LSTM(Long-Short Term Memory)을 사용하는 이유는 무엇인가요?<br/>(i.e. RNN에 비해 LSTM의 좋은 점을 설명해주세요.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y44XfugQ_HR"
      },
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "LSTM은 RNN의 구조에서 기울기 소실 문제를 해결하기 위해 forget, input, output 게이트를 추가한 것으로 뒷쪽 시퀀스의 정보에 비중을 결정함과 동시에 앞쪽 시퀀스 정보를 잃지 않는 않기 때문에 더 좋음. 따라서 RNN에서 일어나는 역전파시 기울기 소실 문제를 추가되는 게이트를 통해 기울기 소실 문제를 해결하는 방법임."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1kzTmDEaLU"
      },
      "source": [
        "#### d) LSTM이나 RNN을 사용하는 예시를 **3개**이상 제시하고 해당되는 경우에 왜 LSTM이나 RNN을 사용하는 것 적절한지 간단하게 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8GPjc_Q_vA"
      },
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "\n",
        "1. 주가예측 : LSTM이 더 좋음. RNN은 재귀적이기 때문에 손실함수의 일차 미분값은 계속해서 감소하기 때문에 결국 소실하기 때문에 주가를 예측하는 과정에서 오차를 측정하는 손실함수가 사라지면 주가 예측의 오차가 매우 커질 수 있기 때문.(장기 메모리를 기억하는 것이 좋음)\n",
        "\n",
        "2. 이메일 스팸 탐지기 : RNN을 사용해도 무관함. 출력과 먼 곳에 있는 데이터를 무시하더라도 스팸메일의 경우 점점 최근의 방식으로 적용되며 변화하기 때문에 장기 메모리는 무시해도 될 것 같음.\n",
        "\n",
        "3. 챗봇 고객 서비스 : LSTM이 더 좋음. 과거의 데이터를 소실하여 출력하게 된다면 오차가 더 커짐."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pP7g8DE0Cz"
      },
      "source": [
        "#### e) 이외에 N324 에서 배운 자연어처리 모델과 관련된 키워드를 3개 이상 적어주세요. <br/> (해당 키워드에 대한 설명은 옵션입니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-sO4mMuRAhp"
      },
      "source": [
        "***이곳에 답안을 입력해주세요***\n",
        "- GPT : Generative Pre-trained Transformer 의 약자로 사전 학습과 관련된 모델\n",
        "- Fine-tuning : 사전 학습이 끝난 모델에 우리가 하고자하는 태스크에 특화된 데이터를 학습하는 과정\n",
        "- BERT : Bidirectional Encoder Representation by Transformer의 약자로 트랜스포머의 인코더만을 사용하여 문맥을 양방향으로 읽어내는 과정.\n",
        "- MLM : BERT 방식의 사전학습에 사용되는 방법\n",
        "- NSP : BERT 방식의 사전학습에 사용되는 방법으로 문맥에 맞는지 아닌지를 판단하여 학습하는 방식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRn44qjhUo9j"
      },
      "source": [
        "# Advanced Goals: 3점을 획득하기 위해선 아래의 조건 중 하나 이상을 만족해야합니다\n",
        " \n",
        "- 2.1 에서 TF-IDF(`TfidfVectorizer`)가 아닌 방법을 사용하여 유사도 검색을 수행해보세요.<br/>\n",
        "TF-IDF와 해당 방법의 차이를 설명해주세요. \n",
        "- 2.2 에서 사용한 방법을 재사용하되 하이퍼 파라미터를 조정하거나 모델 구조를 변경하여 성능을 올려봅시다.<br/>**(주의 : GridSearch, RandomSearch 등의 방법을 사용하여도 좋으나 시간이 오래 걸리므로 범위를 잘 선택해야 합니다.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "lz2uaXFYUo9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb56e68-3501-4c82-aad8-8acc10b21997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 1., 1., 1., 1.]]), array([[424,  11, 177, 400, 324]]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "# 2.1 \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english', max_features=3000)\n",
        "\n",
        "dtm_count = count_vect.fit_transform(df['text'])\n",
        "\n",
        "dtm_count = pd.DataFrame(dtm_count.todense(), columns=count_vect.get_feature_names())\n",
        "dtm_count\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm_count)\n",
        "nn.kneighbors([dtm_tfidf.iloc[42]])\n",
        "\n",
        "# 차이는 TF-IDF 방식은 가중치를 활용하여 모든 단어에 가중을 두는 것이 아닌\n",
        "# 다른 문장에서 나오지 않는 단어에 가중치를 많이 줌으로써 많이 나오는 단어의 가중치를 줄임."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2\n",
        "def model_builder():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "  model.add(GlobalAveragePooling1D()) # 입력되는 단어 벡터의 평균을 구하는 함수입니다.\n",
        "  model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "  model.compile(optimizer='adam', \n",
        "                loss='binary_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ADfcU8YYhPsL"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWvfVk-ZsQy0",
        "outputId": "67b28204-fb0b-4205-9a54-56adf1da3f64"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.8/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "67lVy0c2kgdW"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.wrapper를 활용하여 분류기를 만듭니다\n",
        "model = KerasClassifier(build_fn = model_builder)\n",
        "\n",
        "# GridSearch\n",
        "parameters = {'batch_size': [16, 32],\n",
        "              'epochs': [3],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "\n",
        "grid = GridSearchCV(estimator = model,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 3)\n",
        "grid_result = grid.fit(X_train, y_train, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87_22RMkZh1",
        "outputId": "d9a86dd5-22dc-4c6b-dc1b-0e2b23f162d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1497/1497 [==============================] - 68s 45ms/step - loss: 0.6923 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 2/3\n",
            "1497/1497 [==============================] - 66s 44ms/step - loss: 0.6922 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 3/3\n",
            "1497/1497 [==============================] - 66s 44ms/step - loss: 0.6922 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "749/749 [==============================] - 22s 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1497/1497 [==============================] - 63s 42ms/step - loss: 0.6923 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 2/3\n",
            "1497/1497 [==============================] - 68s 45ms/step - loss: 0.6922 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 3/3\n",
            "1497/1497 [==============================] - 64s 43ms/step - loss: 0.6922 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "749/749 [==============================] - 23s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1497/1497 [==============================] - 65s 42ms/step - loss: 0.6922 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 2/3\n",
            "1497/1497 [==============================] - 64s 43ms/step - loss: 0.6921 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
            "Epoch 3/3\n",
            "1497/1497 [==============================] - 62s 41ms/step - loss: 0.6922 - accuracy: 0.5226 - val_loss: 0.6919 - val_accuracy: 0.5245\n",
            "749/749 [==============================] - 23s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1224/1497 [=======================>......] - ETA: 8s - loss: 0.6924 - accuracy: 0.5207"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "metadata": {
        "id": "E0UFVk5-jj52"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "toc-autonumbering": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}